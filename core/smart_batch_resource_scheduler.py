# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ‰¹å¤„ç†å’ŒåŠ¨æ€èµ„æºè°ƒåº¦å™¨
æœ€å¤§åŒ–ç³»ç»Ÿèµ„æºåˆ©ç”¨ç‡ï¼Œå®ç°åŠ¨æ€è´Ÿè½½å‡è¡¡å’Œæ™ºèƒ½ä»»åŠ¡è°ƒåº¦

ä¸»è¦åŠŸèƒ½ï¼š
1. æ™ºèƒ½æ‰¹å¤„ç†å¤§å°åŠ¨æ€è°ƒæ•´
2. å¤šä»»åŠ¡å¹¶è¡Œæ‰§è¡Œè°ƒåº¦
3. èµ„æºå®æ—¶ç›‘æ§å’Œåˆ†é…
4. è´Ÿè½½å‡è¡¡ç­–ç•¥
5. ä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†
6. è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–
"""

import os
import sys
import time
import threading
import queue
import logging
import gc
import psutil
from typing import Dict, List, Optional, Tuple, Any, Union, Callable, Iterator
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing as mp
from collections import deque
import heapq

import torch
import torch.nn as nn
import numpy as np

try:
    import pynvml
    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4


class ResourceType(Enum):
    """èµ„æºç±»å‹"""
    CPU = "cpu"
    GPU = "gpu"
    MEMORY = "memory"
    DISK_IO = "disk_io"
    NETWORK = "network"


@dataclass
class Task:
    """ä»»åŠ¡å®šä¹‰"""
    task_id: str
    func: Callable
    args: Tuple = ()
    kwargs: Dict = field(default_factory=dict)
    priority: TaskPriority = TaskPriority.NORMAL
    estimated_duration: float = 0.0
    memory_requirement: int = 0  # MB
    gpu_requirement: bool = False
    created_time: float = field(default_factory=time.time)
    deadline: Optional[float] = None
    dependencies: List[str] = field(default_factory=list)
    
    def __lt__(self, other):
        # ç”¨äºä¼˜å…ˆé˜Ÿåˆ—æ’åº
        return (self.priority.value, -self.created_time) > (other.priority.value, -other.created_time)


@dataclass
class ResourceUsage:
    """èµ„æºä½¿ç”¨æƒ…å†µ"""
    cpu_percent: float = 0.0
    memory_percent: float = 0.0
    gpu_memory_percent: Dict[int, float] = field(default_factory=dict)
    gpu_utilization: Dict[int, float] = field(default_factory=dict)
    disk_io_percent: float = 0.0
    network_io_mbps: float = 0.0
    timestamp: float = field(default_factory=time.time)


@dataclass
class BatchConfig:
    """æ‰¹å¤„ç†é…ç½®"""
    min_batch_size: int = 1
    max_batch_size: int = 128
    target_latency_ms: float = 100.0
    target_throughput: float = 1000.0
    memory_limit_mb: int = 8192
    timeout_seconds: float = 30.0
    adaptive_sizing: bool = True


class SmartBatchProcessor:
    """
    æ™ºèƒ½æ‰¹å¤„ç†å™¨
    
    æ ¹æ®ç³»ç»Ÿèµ„æºã€ä»»åŠ¡ç‰¹å¾å’Œæ€§èƒ½ç›®æ ‡åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†ç­–ç•¥
    """
    
    def __init__(self, config: BatchConfig = None):
        self.config = config or BatchConfig()
        self.logger = self._setup_logger()
        
        # æ‰¹å¤„ç†å†å²ç»Ÿè®¡
        self.batch_history: deque = deque(maxlen=100)
        self.performance_metrics: Dict[int, List[float]] = {}  # batch_size -> [latency, throughput]
        
        # åŠ¨æ€å‚æ•°
        self.current_optimal_batch_size = self.config.min_batch_size
        self.learning_rate = 0.1
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.pending_tasks: queue.Queue = queue.Queue()
        self.processing = False
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—å™¨"""
        logger = logging.getLogger("SmartBatchProcessor")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '[%(asctime)s] [æ™ºèƒ½æ‰¹å¤„ç†å™¨] %(levelname)s: %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def add_task(self, task: Task):
        """æ·»åŠ ä»»åŠ¡åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        self.pending_tasks.put(task)
        
    def start_processing(self):
        """å¯åŠ¨æ‰¹å¤„ç†"""
        if self.processing:
            return
            
        self.processing = True
        self.processing_thread = threading.Thread(target=self._process_batches, daemon=True)
        self.processing_thread.start()
        self.logger.info("æ™ºèƒ½æ‰¹å¤„ç†å™¨å·²å¯åŠ¨")
    
    def stop_processing(self):
        """åœæ­¢æ‰¹å¤„ç†"""
        self.processing = False
        self.logger.info("æ™ºèƒ½æ‰¹å¤„ç†å™¨å·²åœæ­¢")
    
    def _process_batches(self):
        """æ‰¹å¤„ç†ä¸»å¾ªç¯"""
        while self.processing:
            try:
                # æ”¶é›†ä¸€æ‰¹ä»»åŠ¡
                batch = self._collect_batch()
                if not batch:
                    time.sleep(0.01)  # æ²¡æœ‰ä»»åŠ¡æ—¶çŸ­æš‚ç­‰å¾…
                    continue
                
                # æ‰§è¡Œæ‰¹å¤„ç†
                start_time = time.time()
                results = self._execute_batch(batch)
                end_time = time.time()
                
                # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                batch_size = len(batch)
                latency = (end_time - start_time) * 1000  # ms
                throughput = batch_size / (end_time - start_time)  # tasks/sec
                
                self._update_performance_metrics(batch_size, latency, throughput)
                self._adapt_batch_size(batch_size, latency, throughput)
                
                self.logger.debug(f"æ‰¹å¤„ç†å®Œæˆ: å¤§å°={batch_size}, å»¶è¿Ÿ={latency:.1f}ms, ååé‡={throughput:.1f} tasks/sec")
                
            except Exception as e:
                self.logger.error(f"æ‰¹å¤„ç†å‡ºé”™: {e}")
                time.sleep(0.1)
    
    def _collect_batch(self) -> List[Task]:
        """æ”¶é›†ä¸€æ‰¹ä»»åŠ¡"""
        batch = []
        batch_memory = 0
        start_time = time.time()
        
        while (len(batch) < self.current_optimal_batch_size and 
               batch_memory < self.config.memory_limit_mb and
               time.time() - start_time < self.config.timeout_seconds):
            
            try:
                task = self.pending_tasks.get(timeout=0.01)
                
                # æ£€æŸ¥å†…å­˜éœ€æ±‚
                if batch_memory + task.memory_requirement <= self.config.memory_limit_mb:
                    batch.append(task)
                    batch_memory += task.memory_requirement
                else:
                    # å†…å­˜ä¸è¶³ï¼Œæ”¾å›é˜Ÿåˆ—
                    self.pending_tasks.put(task)
                    break
                    
            except queue.Empty:
                break
        
        return batch
    
    def _execute_batch(self, batch: List[Task]) -> List[Any]:
        """æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡"""
        results = []
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        batch.sort(key=lambda t: t.priority, reverse=True)
        
        # åˆ†ç»„æ‰§è¡Œ
        gpu_tasks = [t for t in batch if t.gpu_requirement]
        cpu_tasks = [t for t in batch if not t.gpu_requirement]
        
        # å¹¶è¡Œæ‰§è¡ŒGPUå’ŒCPUä»»åŠ¡
        if gpu_tasks and cpu_tasks:
            with ThreadPoolExecutor(max_workers=2) as executor:
                gpu_future = executor.submit(self._execute_gpu_tasks, gpu_tasks)
                cpu_future = executor.submit(self._execute_cpu_tasks, cpu_tasks)
                
                gpu_results = gpu_future.result()
                cpu_results = cpu_future.result()
                
                results.extend(gpu_results)
                results.extend(cpu_results)
        else:
            if gpu_tasks:
                results.extend(self._execute_gpu_tasks(gpu_tasks))
            if cpu_tasks:
                results.extend(self._execute_cpu_tasks(cpu_tasks))
        
        return results
    
    def _execute_gpu_tasks(self, tasks: List[Task]) -> List[Any]:
        """æ‰§è¡ŒGPUä»»åŠ¡"""
        results = []
        for task in tasks:
            try:
                result = task.func(*task.args, **task.kwargs)
                results.append(result)
            except Exception as e:
                self.logger.error(f"GPUä»»åŠ¡ {task.task_id} æ‰§è¡Œå¤±è´¥: {e}")
                results.append(None)
        return results
    
    def _execute_cpu_tasks(self, tasks: List[Task]) -> List[Any]:
        """æ‰§è¡ŒCPUä»»åŠ¡"""
        results = []
        max_workers = min(len(tasks), mp.cpu_count())
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(task.func, *task.args, **task.kwargs): task 
                      for task in tasks}
            
            for future in as_completed(futures):
                task = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    self.logger.error(f"CPUä»»åŠ¡ {task.task_id} æ‰§è¡Œå¤±è´¥: {e}")
                    results.append(None)
        
        return results
    
    def _update_performance_metrics(self, batch_size: int, latency: float, throughput: float):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        if batch_size not in self.performance_metrics:
            self.performance_metrics[batch_size] = []
        
        self.performance_metrics[batch_size].append((latency, throughput))
        
        # ä¿æŒæœ€è¿‘çš„10ä¸ªè®°å½•
        if len(self.performance_metrics[batch_size]) > 10:
            self.performance_metrics[batch_size] = self.performance_metrics[batch_size][-10:]
    
    def _adapt_batch_size(self, batch_size: int, latency: float, throughput: float):
        """è‡ªé€‚åº”è°ƒæ•´æ‰¹å¤„ç†å¤§å°"""
        if not self.config.adaptive_sizing:
            return
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ€§èƒ½ç›®æ ‡
        latency_ok = latency <= self.config.target_latency_ms
        throughput_ok = throughput >= self.config.target_throughput
        
        if latency_ok and throughput_ok:
            # æ€§èƒ½è‰¯å¥½ï¼Œå°è¯•å¢åŠ æ‰¹å¤„ç†å¤§å°
            if batch_size < self.config.max_batch_size:
                self.current_optimal_batch_size = min(
                    self.config.max_batch_size,
                    int(batch_size * (1 + self.learning_rate))
                )
        elif not latency_ok:
            # å»¶è¿Ÿè¿‡é«˜ï¼Œå‡å°‘æ‰¹å¤„ç†å¤§å°
            self.current_optimal_batch_size = max(
                self.config.min_batch_size,
                int(batch_size * (1 - self.learning_rate))
            )
        elif not throughput_ok:
            # ååé‡ä¸è¶³ï¼Œå°è¯•å¢åŠ æ‰¹å¤„ç†å¤§å°
            if batch_size < self.config.max_batch_size:
                self.current_optimal_batch_size = min(
                    self.config.max_batch_size,
                    int(batch_size * (1 + self.learning_rate * 0.5))
                )
    
    def get_optimal_batch_size(self) -> int:
        """è·å–å½“å‰æœ€ä¼˜æ‰¹å¤„ç†å¤§å°"""
        return self.current_optimal_batch_size
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_metrics:
            return {}
        
        stats = {}
        for batch_size, metrics in self.performance_metrics.items():
            latencies = [m[0] for m in metrics]
            throughputs = [m[1] for m in metrics]
            
            stats[batch_size] = {
                'avg_latency': sum(latencies) / len(latencies),
                'avg_throughput': sum(throughputs) / len(throughputs),
                'samples': len(metrics)
            }
        
        return stats


class ResourceMonitor:
    """
    èµ„æºç›‘æ§å™¨
    
    å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µï¼Œä¸ºè°ƒåº¦å†³ç­–æä¾›æ•°æ®æ”¯æŒ
    """
    
    def __init__(self, update_interval: float = 1.0):
        self.update_interval = update_interval
        self.logger = self._setup_logger()
        
        # ç›‘æ§çŠ¶æ€
        self.monitoring = False
        self.monitor_thread = None
        
        # èµ„æºå†å²
        self.resource_history: deque = deque(maxlen=300)  # 5åˆ†é’Ÿå†å²ï¼ˆæ¯ç§’ä¸€ä¸ªï¼‰
        self.current_usage = ResourceUsage()
        
        # NVMLåˆå§‹åŒ–
        self.nvml_available = False
        if PYNVML_AVAILABLE:
            try:
                pynvml.nvmlInit()
                self.nvml_available = True
                self.gpu_count = pynvml.nvmlDeviceGetCount()
            except Exception as e:
                self.logger.warning(f"NVMLåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—å™¨"""
        logger = logging.getLogger("ResourceMonitor")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '[%(asctime)s] [èµ„æºç›‘æ§å™¨] %(levelname)s: %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.logger.info("èµ„æºç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)
        self.logger.info("èµ„æºç›‘æ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        while self.monitoring:
            try:
                usage = self._collect_resource_usage()
                self.current_usage = usage
                self.resource_history.append(usage)
                
                time.sleep(self.update_interval)
                
            except Exception as e:
                self.logger.error(f"èµ„æºç›‘æ§å‡ºé”™: {e}")
                time.sleep(self.update_interval)
    
    def _collect_resource_usage(self) -> ResourceUsage:
        """æ”¶é›†èµ„æºä½¿ç”¨æƒ…å†µ"""
        usage = ResourceUsage()
        
        # CPUä½¿ç”¨ç‡
        usage.cpu_percent = psutil.cpu_percent(interval=None)
        
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        usage.memory_percent = memory.percent
        
        # GPUä½¿ç”¨æƒ…å†µ
        if self.nvml_available:
            for i in range(self.gpu_count):
                try:
                    handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                    
                    # GPUåˆ©ç”¨ç‡
                    util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                    usage.gpu_utilization[i] = util.gpu
                    
                    # GPUå†…å­˜ä½¿ç”¨ç‡
                    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                    usage.gpu_memory_percent[i] = (mem_info.used / mem_info.total) * 100
                    
                except Exception as e:
                    self.logger.debug(f"è·å–GPU {i} ä¿¡æ¯å¤±è´¥: {e}")
        
        # ç£ç›˜IO
        disk_io = psutil.disk_io_counters()
        if disk_io:
            usage.disk_io_percent = 0  # ç®€åŒ–å®ç°
        
        # ç½‘ç»œIO
        net_io = psutil.net_io_counters()
        if net_io:
            usage.network_io_mbps = (net_io.bytes_sent + net_io.bytes_recv) / (1024 * 1024)
        
        return usage
    
    def get_current_usage(self) -> ResourceUsage:
        """è·å–å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ"""
        return self.current_usage
    
    def get_average_usage(self, minutes: int = 5) -> ResourceUsage:
        """è·å–å¹³å‡èµ„æºä½¿ç”¨æƒ…å†µ"""
        if not self.resource_history:
            return self.current_usage
        
        samples = min(minutes * 60 // self.update_interval, len(self.resource_history))
        recent_usage = list(self.resource_history)[-samples:]
        
        avg_usage = ResourceUsage()
        avg_usage.cpu_percent = sum(u.cpu_percent for u in recent_usage) / len(recent_usage)
        avg_usage.memory_percent = sum(u.memory_percent for u in recent_usage) / len(recent_usage)
        
        # GPUå¹³å‡ä½¿ç”¨ç‡
        for gpu_id in self.current_usage.gpu_utilization:
            gpu_utils = [u.gpu_utilization.get(gpu_id, 0) for u in recent_usage]
            avg_usage.gpu_utilization[gpu_id] = sum(gpu_utils) / len(gpu_utils)
            
            gpu_mems = [u.gpu_memory_percent.get(gpu_id, 0) for u in recent_usage]
            avg_usage.gpu_memory_percent[gpu_id] = sum(gpu_mems) / len(gpu_mems)
        
        return avg_usage
    
    def is_resource_available(self, resource_type: ResourceType, threshold: float = 80.0) -> bool:
        """æ£€æŸ¥èµ„æºæ˜¯å¦å¯ç”¨"""
        usage = self.current_usage
        
        if resource_type == ResourceType.CPU:
            return usage.cpu_percent < threshold
        elif resource_type == ResourceType.MEMORY:
            return usage.memory_percent < threshold
        elif resource_type == ResourceType.GPU:
            return any(util < threshold for util in usage.gpu_utilization.values())
        
        return True
    
    def get_best_gpu(self) -> Optional[int]:
        """è·å–æœ€ç©ºé—²çš„GPU"""
        if not self.current_usage.gpu_utilization:
            return None
        
        best_gpu = min(self.current_usage.gpu_utilization.items(), 
                      key=lambda x: x[1])
        return best_gpu[0]


class DynamicResourceScheduler:
    """
    åŠ¨æ€èµ„æºè°ƒåº¦å™¨
    
    æ ¹æ®å®æ—¶èµ„æºçŠ¶å†µå’Œä»»åŠ¡éœ€æ±‚è¿›è¡Œæ™ºèƒ½è°ƒåº¦
    """
    
    def __init__(self):
        self.logger = self._setup_logger()
        
        # ç»„ä»¶
        self.resource_monitor = ResourceMonitor()
        self.batch_processor = SmartBatchProcessor()
        
        # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        self.task_queue: List[Task] = []
        self.completed_tasks: Dict[str, Any] = {}
        self.failed_tasks: Dict[str, str] = {}
        
        # è°ƒåº¦çŠ¶æ€
        self.scheduling = False
        self.scheduler_thread = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.total_tasks_processed = 0
        self.total_processing_time = 0.0
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—å™¨"""
        logger = logging.getLogger("DynamicResourceScheduler")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '[%(asctime)s] [åŠ¨æ€èµ„æºè°ƒåº¦å™¨] %(levelname)s: %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def start_scheduler(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.scheduling:
            return
        
        self.resource_monitor.start_monitoring()
        self.batch_processor.start_processing()
        
        self.scheduling = True
        self.scheduler_thread = threading.Thread(target=self._schedule_loop, daemon=True)
        self.scheduler_thread.start()
        
        self.logger.info("åŠ¨æ€èµ„æºè°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop_scheduler(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.scheduling = False
        
        self.resource_monitor.stop_monitoring()
        self.batch_processor.stop_processing()
        
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=3.0)
        
        self.logger.info("åŠ¨æ€èµ„æºè°ƒåº¦å™¨å·²åœæ­¢")
    
    def submit_task(self, task: Task) -> str:
        """æäº¤ä»»åŠ¡"""
        heapq.heappush(self.task_queue, task)
        self.logger.debug(f"ä»»åŠ¡ {task.task_id} å·²æäº¤ (ä¼˜å…ˆçº§: {task.priority.name})")
        return task.task_id
    
    def get_task_result(self, task_id: str) -> Optional[Any]:
        """è·å–ä»»åŠ¡ç»“æœ"""
        return self.completed_tasks.get(task_id)
    
    def _schedule_loop(self):
        """è°ƒåº¦ä¸»å¾ªç¯"""
        while self.scheduling:
            try:
                if not self.task_queue:
                    time.sleep(0.1)
                    continue
                
                # è·å–èµ„æºçŠ¶å†µ
                current_usage = self.resource_monitor.get_current_usage()
                
                # é€‰æ‹©åˆé€‚çš„ä»»åŠ¡æ‰§è¡Œ
                ready_tasks = self._select_ready_tasks(current_usage)
                
                if ready_tasks:
                    # æäº¤åˆ°æ‰¹å¤„ç†å™¨
                    for task in ready_tasks:
                        self.batch_processor.add_task(task)
                        self.task_queue.remove(task)
                        heapq.heapify(self.task_queue)  # é‡æ–°å †åŒ–
                
                time.sleep(0.05)  # è°ƒåº¦é—´éš”
                
            except Exception as e:
                self.logger.error(f"è°ƒåº¦å¾ªç¯å‡ºé”™: {e}")
                time.sleep(0.1)
    
    def _select_ready_tasks(self, current_usage: ResourceUsage, max_tasks: int = 10) -> List[Task]:
        """é€‰æ‹©å‡†å¤‡æ‰§è¡Œçš„ä»»åŠ¡"""
        ready_tasks = []
        
        for task in sorted(self.task_queue)[:max_tasks]:
            # æ£€æŸ¥ä¾èµ–
            if not self._check_dependencies(task):
                continue
            
            # æ£€æŸ¥èµ„æºéœ€æ±‚
            if not self._check_resource_requirements(task, current_usage):
                continue
            
            # æ£€æŸ¥æˆªæ­¢æ—¶é—´
            if task.deadline and time.time() > task.deadline:
                self.failed_tasks[task.task_id] = "ä»»åŠ¡è¶…æ—¶"
                continue
            
            ready_tasks.append(task)
            
            # é™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°
            if len(ready_tasks) >= 5:
                break
        
        return ready_tasks
    
    def _check_dependencies(self, task: Task) -> bool:
        """æ£€æŸ¥ä»»åŠ¡ä¾èµ–"""
        for dep_id in task.dependencies:
            if dep_id not in self.completed_tasks:
                return False
        return True
    
    def _check_resource_requirements(self, task: Task, current_usage: ResourceUsage) -> bool:
        """æ£€æŸ¥èµ„æºéœ€æ±‚"""
        # æ£€æŸ¥GPUéœ€æ±‚
        if task.gpu_requirement:
            if not any(util < 80.0 for util in current_usage.gpu_utilization.values()):
                return False
        
        # æ£€æŸ¥å†…å­˜éœ€æ±‚
        if task.memory_requirement > 0:
            available_memory = psutil.virtual_memory().available / (1024 * 1024)  # MB
            if task.memory_requirement > available_memory * 0.8:  # ä¿ç•™20%å†…å­˜
                return False
        
        # æ£€æŸ¥CPUéœ€æ±‚
        if current_usage.cpu_percent > 90.0:
            return False
        
        return True
    
    def get_scheduler_stats(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯"""
        current_usage = self.resource_monitor.get_current_usage()
        avg_usage = self.resource_monitor.get_average_usage()
        batch_stats = self.batch_processor.get_performance_stats()
        
        return {
            "task_stats": {
                "pending_tasks": len(self.task_queue),
                "completed_tasks": len(self.completed_tasks),
                "failed_tasks": len(self.failed_tasks),
                "total_processed": self.total_tasks_processed
            },
            "resource_usage": {
                "current": {
                    "cpu_percent": current_usage.cpu_percent,
                    "memory_percent": current_usage.memory_percent,
                    "gpu_utilization": current_usage.gpu_utilization,
                    "gpu_memory_percent": current_usage.gpu_memory_percent
                },
                "average": {
                    "cpu_percent": avg_usage.cpu_percent,
                    "memory_percent": avg_usage.memory_percent,
                    "gpu_utilization": avg_usage.gpu_utilization,
                    "gpu_memory_percent": avg_usage.gpu_memory_percent
                }
            },
            "batch_performance": batch_stats,
            "optimal_batch_size": self.batch_processor.get_optimal_batch_size()
        }


class ComputeEfficiencyIntegrator:
    """
    è®¡ç®—æ•ˆç‡é›†æˆå™¨
    
    æ•´åˆæ‰€æœ‰ä¼˜åŒ–ç»„ä»¶ï¼Œæä¾›ç»Ÿä¸€çš„é«˜çº§æ¥å£
    """
    
    def __init__(self):
        self.logger = self._setup_logger()
        
        # æ ¸å¿ƒç»„ä»¶
        self.scheduler = DynamicResourceScheduler()
        
        # é›†æˆçŠ¶æ€
        self.integrated_systems: Dict[str, Any] = {}
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—å™¨"""
        logger = logging.getLogger("ComputeEfficiencyIntegrator")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '[%(asctime)s] [è®¡ç®—æ•ˆç‡é›†æˆå™¨] %(levelname)s: %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def initialize_maximum_efficiency_mode(self):
        """åˆå§‹åŒ–æœ€å¤§æ•ˆç‡æ¨¡å¼"""
        self.logger.info("ğŸš€ åˆå§‹åŒ–è®¡ç®—æ•ˆç‡æœ€å¤§åŒ–æ¨¡å¼")
        
        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start_scheduler()
        
        # ä¼˜åŒ–ç³»ç»Ÿè®¾ç½®
        self._optimize_system_settings()
        
        self.logger.info("âœ… è®¡ç®—æ•ˆç‡æœ€å¤§åŒ–æ¨¡å¼å·²å¯ç”¨")
    
    def _optimize_system_settings(self):
        """ä¼˜åŒ–ç³»ç»Ÿè®¾ç½®"""
        try:
            # è®¾ç½®PyTorchæ€§èƒ½ä¼˜åŒ–
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.enabled = True
            
            # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ¨¡å¼ï¼‰
            torch.set_grad_enabled(False)
            
            # å†…å­˜ä¼˜åŒ–è®¾ç½®
            if torch.cuda.is_available():
                # å¯ç”¨å†…å­˜æ± 
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
                
                # æ¸…ç†ç¼“å­˜
                torch.cuda.empty_cache()
            
            self.logger.info("ç³»ç»Ÿè®¾ç½®ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.warning(f"ç³»ç»Ÿè®¾ç½®ä¼˜åŒ–å¤±è´¥: {e}")
    
    def submit_compute_task(self, 
                           func: Callable, 
                           *args, 
                           priority: TaskPriority = TaskPriority.NORMAL,
                           gpu_required: bool = False,
                           memory_mb: int = 0,
                           **kwargs) -> str:
        """æäº¤è®¡ç®—ä»»åŠ¡"""
        task_id = f"task_{int(time.time() * 1000000)}"
        
        task = Task(
            task_id=task_id,
            func=func,
            args=args,
            kwargs=kwargs,
            priority=priority,
            gpu_requirement=gpu_required,
            memory_requirement=memory_mb
        )
        
        return self.scheduler.submit_task(task)
    
    def get_efficiency_report(self) -> Dict[str, Any]:
        """è·å–æ•ˆç‡æŠ¥å‘Š"""
        stats = self.scheduler.get_scheduler_stats()
        
        # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
        current_usage = stats["resource_usage"]["current"]
        avg_usage = stats["resource_usage"]["average"]
        
        # ç»¼åˆæ•ˆç‡è¯„åˆ† (0-100)
        efficiency_score = self._calculate_efficiency_score(current_usage, avg_usage)
        
        return {
            "efficiency_score": efficiency_score,
            "resource_utilization": stats["resource_usage"],
            "task_throughput": stats["task_stats"],
            "batch_optimization": stats["batch_performance"],
            "recommendations": self._generate_efficiency_recommendations(stats)
        }
    
    def _calculate_efficiency_score(self, current: Dict, average: Dict) -> float:
        """è®¡ç®—æ•ˆç‡è¯„åˆ†"""
        # åŸºäºèµ„æºåˆ©ç”¨ç‡å’Œä»»åŠ¡ååé‡çš„ç»¼åˆè¯„åˆ†
        cpu_score = min(100, current["cpu_percent"])
        memory_score = min(100, current["memory_percent"])
        
        # GPUè¯„åˆ†
        gpu_score = 0
        if current["gpu_utilization"]:
            gpu_scores = list(current["gpu_utilization"].values())
            gpu_score = sum(gpu_scores) / len(gpu_scores)
        
        # ç»¼åˆè¯„åˆ†
        if gpu_score > 0:
            efficiency_score = (cpu_score * 0.3 + memory_score * 0.3 + gpu_score * 0.4)
        else:
            efficiency_score = (cpu_score * 0.5 + memory_score * 0.5)
        
        return min(100.0, efficiency_score)
    
    def _generate_efficiency_recommendations(self, stats: Dict) -> List[str]:
        """ç”Ÿæˆæ•ˆç‡ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        current = stats["resource_usage"]["current"]
        
        # CPUå»ºè®®
        if current["cpu_percent"] < 30:
            recommendations.append("CPUåˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯è€ƒè™‘å¢åŠ å¹¶è¡Œä»»åŠ¡æ•°")
        elif current["cpu_percent"] > 90:
            recommendations.append("CPUè´Ÿè½½è¿‡é«˜ï¼Œå»ºè®®å‡å°‘å¹¶å‘ä»»åŠ¡æˆ–ä¼˜åŒ–ç®—æ³•")
        
        # å†…å­˜å»ºè®®
        if current["memory_percent"] < 50:
            recommendations.append("å†…å­˜åˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯å¢åŠ æ‰¹å¤„ç†å¤§å°æˆ–ç¼“å­˜")
        elif current["memory_percent"] > 85:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ç®¡ç†")
        
        # GPUå»ºè®®
        for gpu_id, util in current["gpu_utilization"].items():
            if util < 30:
                recommendations.append(f"GPU {gpu_id} åˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯ä¼˜åŒ–GPUä»»åŠ¡åˆ†é…")
            elif util > 90:
                recommendations.append(f"GPU {gpu_id} è´Ÿè½½è¿‡é«˜ï¼Œæ³¨æ„æ•£çƒ­å’Œç¨³å®šæ€§")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ•ˆç‡è‰¯å¥½ï¼Œå„é¡¹èµ„æºåˆ©ç”¨ç‡å‡è¡¡")
        
        return recommendations
    
    def shutdown(self):
        """å…³é—­é›†æˆå™¨"""
        self.scheduler.stop_scheduler()
        self.logger.info("è®¡ç®—æ•ˆç‡é›†æˆå™¨å·²å…³é—­")


# å…¨å±€é›†æˆå™¨å®ä¾‹
_global_efficiency_integrator = None

def get_efficiency_integrator() -> ComputeEfficiencyIntegrator:
    """è·å–å…¨å±€æ•ˆç‡é›†æˆå™¨"""
    global _global_efficiency_integrator
    if _global_efficiency_integrator is None:
        _global_efficiency_integrator = ComputeEfficiencyIntegrator()
    return _global_efficiency_integrator


def enable_maximum_compute_efficiency():
    """å¯ç”¨æœ€å¤§è®¡ç®—æ•ˆç‡æ¨¡å¼"""
    integrator = get_efficiency_integrator()
    integrator.initialize_maximum_efficiency_mode()
    return integrator


if __name__ == "__main__":
    # æµ‹è¯•æ™ºèƒ½æ‰¹å¤„ç†å’Œèµ„æºè°ƒåº¦
    print("ğŸš€ æµ‹è¯•æ™ºèƒ½æ‰¹å¤„ç†å’ŒåŠ¨æ€èµ„æºè°ƒåº¦å™¨...")
    
    # å¯ç”¨æœ€å¤§æ•ˆç‡æ¨¡å¼
    integrator = enable_maximum_compute_efficiency()
    
    # æäº¤æµ‹è¯•ä»»åŠ¡
    def test_task(x, y):
        import time
        time.sleep(0.1)  # æ¨¡æ‹Ÿè®¡ç®—
        return x + y
    
    task_ids = []
    for i in range(10):
        task_id = integrator.submit_compute_task(
            test_task, i, i*2, 
            priority=TaskPriority.NORMAL,
            memory_mb=100
        )
        task_ids.append(task_id)
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    time.sleep(3)
    
    # è·å–æ•ˆç‡æŠ¥å‘Š
    report = integrator.get_efficiency_report()
    print(f"ğŸ“Š æ•ˆç‡æŠ¥å‘Š: {report}")
    
    # å…³é—­
    integrator.shutdown()
    
    print("æµ‹è¯•å®Œæˆ")
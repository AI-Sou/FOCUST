#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import csv
import pandas as pd
import re
from pathlib import Path

# ç±»åˆ«IDåˆ°åç§°çš„æ˜ å°„
CLASS_MAPPING = {
    "1": "é‡‘é»„è‘¡è„çƒèŒPCA",
    "2": "é‡‘é»„è‘¡è„çƒèŒBairdParker",
    "3": "å¤§è‚ æ†èŒPCA",
    "4": "æ²™é—¨æ°èŒPCA",
    "5": "å¤§è‚ æ†èŒVRBA"
}

# è‹±æ–‡ç±»åˆ«æ˜ å°„ï¼ˆç”¨äºå¯èƒ½çš„è‹±æ–‡ç‰ˆæœ¬ï¼‰
CLASS_MAPPING_EN = {
    "1": "S.aureus PCA",
    "2": "S.aureus Baird-Parker",
    "3": "E.coli PCA",
    "4": "Salmonella PCA",
    "5": "E.coli VRBA"
}

def update_json_file(file_path):
    """æ›´æ–°JSONæ–‡æ¡£ä¸­çš„ç±»åˆ«ID"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # å°è¯•è§£æä¸ºJSON
        try:
            data = json.loads(content)

            # é€’å½’éå†JSONç»“æ„å¹¶æ›¿æ¢ç±»åˆ«ID
            def replace_class_ids(obj):
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        obj[key] = replace_class_ids(value)
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        obj[i] = replace_class_ids(item)
                elif isinstance(obj, str):
                    # æ›¿æ¢æ•°å­—IDä¸ºä¸­æ–‡åç§°
                    if obj in CLASS_MAPPING:
                        return CLASS_MAPPING[obj]
                    # æ›¿æ¢è‹±æ–‡ç±»åˆ«IDä¸ºä¸­æ–‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    elif obj in CLASS_MAPPING_EN.values():
                        for en_name, cn_name in zip(CLASS_MAPPING_EN.values(), CLASS_MAPPING.values()):
                            if obj == en_name:
                                return cn_name
                return obj

            # æ‰§è¡Œæ›¿æ¢
            updated_data = replace_class_ids(data)

            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(updated_data, f, indent=2, ensure_ascii=False)

            return True

        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå°è¯•æ–‡æœ¬æ›¿æ¢
            updated_content = content
            for class_id, class_name in CLASS_MAPPING.items():
                # æ›¿æ¢å„ç§æ ¼å¼çš„ç±»åˆ«ID
                patterns = [
                    f'"{class_id}"',           # "1"
                    f"'{class_id}'",           # '1'
                    f': {class_id},',          # : 1,
                    f': {class_id}\n',         # : 1\n
                    f'"class": "{class_id}"',  # "class": "1"
                    f'class": {class_id}',     # class: 1
                ]

                for pattern in patterns:
                    updated_content = updated_content.replace(pattern, f'"{class_name}"')

            # ä¿å­˜æ›´æ–°åçš„å†…å®¹
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)

            return True

    except Exception as e:
        print(f"å¤„ç†JSONæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        return False

def update_excel_file(file_path):
    """æ›´æ–°Excelæ–‡ä»¶ä¸­çš„ç±»åˆ«ID"""
    try:
        # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
        excel_file = pd.ExcelFile(file_path)
        updated_sheets = {}

        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(file_path, sheet_name=sheet_name)

            # æ›¿æ¢DataFrameä¸­çš„ç±»åˆ«ID
            for col in df.columns:
                df[col] = df[col].astype(str).replace(CLASS_MAPPING)

            updated_sheets[sheet_name] = df

        # ä¿å­˜æ›´æ–°åçš„Excelæ–‡ä»¶
        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
            for sheet_name, df in updated_sheets.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)

        return True

    except Exception as e:
        print(f"å¤„ç†Excelæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        return False

def update_csv_file(file_path):
    """æ›´æ–°CSVæ–‡ä»¶ä¸­çš„ç±»åˆ«ID"""
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(file_path, encoding='utf-8')

        # æ›¿æ¢DataFrameä¸­çš„ç±»åˆ«ID
        for col in df.columns:
            df[col] = df[col].astype(str).replace(CLASS_MAPPING)

        # ä¿å­˜æ›´æ–°åçš„CSVæ–‡ä»¶
        df.to_csv(file_path, index=False, encoding='utf-8')

        return True

    except Exception as e:
        print(f"å¤„ç†CSVæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        return False

def update_all_files(root_dir):
    """é€’å½’æ›´æ–°æ‰€æœ‰æ–‡ä»¶ä¸­çš„ç±»åˆ«ID"""
    root_path = Path(root_dir)

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'json': {'total': 0, 'success': 0},
        'excel': {'total': 0, 'success': 0},
        'csv': {'total': 0, 'success': 0}
    }

    print(f"å¼€å§‹æ›´æ–°ç›®å½•: {root_dir}")
    print("ç±»åˆ«æ˜ å°„:")
    for class_id, class_name in CLASS_MAPPING.items():
        print(f"  {class_id} -> {class_name}")
    print()

    # éå†æ‰€æœ‰æ–‡ä»¶
    for file_path in root_path.rglob('*'):
        if file_path.is_file():
            file_lower = str(file_path).lower()

            # å¤„ç†JSONæ–‡ä»¶
            if file_lower.endswith('.json'):
                stats['json']['total'] += 1
                if update_json_file(file_path):
                    stats['json']['success'] += 1
                    print(f"âœ“ JSON: {file_path.relative_to(root_path)}")
                else:
                    print(f"âœ— JSON: {file_path.relative_to(root_path)}")

            # å¤„ç†Excelæ–‡ä»¶
            elif file_lower.endswith('.xlsx') or file_lower.endswith('.xls'):
                stats['excel']['total'] += 1
                if update_excel_file(file_path):
                    stats['excel']['success'] += 1
                    print(f"âœ“ Excel: {file_path.relative_to(root_path)}")
                else:
                    print(f"âœ— Excel: {file_path.relative_to(root_path)}")

            # å¤„ç†CSVæ–‡ä»¶
            elif file_lower.endswith('.csv'):
                stats['csv']['total'] += 1
                if update_csv_file(file_path):
                    stats['csv']['success'] += 1
                    print(f"âœ“ CSV: {file_path.relative_to(root_path)}")
                else:
                    print(f"âœ— CSV: {file_path.relative_to(root_path)}")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("æ›´æ–°å®Œæˆç»Ÿè®¡:")
    print(f"JSONæ–‡ä»¶: {stats['json']['success']}/{stats['json']['total']} æˆåŠŸ")
    print(f"Excelæ–‡ä»¶: {stats['excel']['success']}/{stats['excel']['total']} æˆåŠŸ")
    print(f"CSVæ–‡ä»¶: {stats['csv']['success']}/{stats['csv']['total']} æˆåŠŸ")
    print(f"æ€»è®¡: {stats['json']['success']+stats['excel']['success']+stats['csv']['success']}/{stats['json']['total']+stats['excel']['total']+stats['csv']['total']} æˆåŠŸ")
    print("="*60)

def verify_updates(root_dir):
    """éªŒè¯æ›´æ–°ç»“æœ"""
    print("\néªŒè¯æ›´æ–°ç»“æœ...")

    # æŸ¥æ‰¾ä¸€äº›å…³é”®æ–‡ä»¶è¿›è¡Œæ£€æŸ¥
    sample_files = [
        "evaluation_run_20251102_233045/dual_mode_analysis/dual_mode_comparison_report.json",
        "evaluation_run_20251102_233045/evaluation_iou_sweep_report_overall.csv",
        "evaluation_run_20251102_233045/dual_mode_with_filter/complete_evaluation_report_20251103_000249.xlsx"
    ]

    for file_path in sample_files:
        full_path = root_path / file_path
        if full_path.exists():
            print(f"\næ£€æŸ¥æ–‡ä»¶: {file_path}")

            try:
                if file_path.endswith('.json'):
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ•°å­—ç±»åˆ«ID
                        found_ids = []
                        for class_id in CLASS_MAPPING.keys():
                            if f'"{class_id}"' in content or f"'{class_id}'" in content:
                                found_ids.append(class_id)

                        if found_ids:
                            print(f"  âš ï¸ ä»å‘ç°ç±»åˆ«ID: {found_ids}")
                        else:
                            print(f"  âœ“ æœªå‘ç°æ•°å­—ç±»åˆ«ID")

                elif file_path.endswith('.csv'):
                    df = pd.read_csv(full_path, encoding='utf-8')
                    # æ£€æŸ¥DataFrameä¸­æ˜¯å¦è¿˜æœ‰æ•°å­—ç±»åˆ«ID
                    found_ids = []
                    for col in df.columns:
                        for val in df[col].astype(str).unique():
                            if val in CLASS_MAPPING.keys():
                                found_ids.append(val)

                    if found_ids:
                        print(f"  âš ï¸ä»å‘ç°ç±»åˆ«ID: {set(found_ids)}")
                    else:
                        print(f"  âœ“ æœªå‘ç°æ•°å­—ç±»åˆ«ID")

            except Exception as e:
                print(f"  âœ— æ£€æŸ¥å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # è®¾ç½®è¦æ›´æ–°çš„æ ¹ç›®å½•
    root_directory = "evaluation_run_20251102_233045"

    if not os.path.exists(root_directory):
        print(f"é”™è¯¯: ç›®å½• {root_directory} ä¸å­˜åœ¨")
        exit(1)

    # æ‰§è¡Œæ›´æ–°
    update_all_files(root_directory)

    # éªŒè¯ç»“æœ
    verify_updates(Path(root_directory))

    print(f"\nğŸ‰ ç±»åˆ«åç§°æ›´æ–°å®Œæˆï¼")
    print(f"æ‰€æœ‰æ–‡ä»¶ä¸­çš„æ•°å­—ç±»åˆ«IDå·²æ›¿æ¢ä¸ºå¯¹åº”çš„ä¸­æ–‡åç§°ã€‚")

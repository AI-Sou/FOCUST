# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹çš„ä¼ªåºåˆ—ç”Ÿæˆå·¥å…·
å¯ä»¥ä¸ºåŒä¸€ä¸ªç±»åˆ«åŒæ—¶ç”Ÿæˆä¸¤ç§ç±»å‹çš„ä¼ªåºåˆ—ï¼š
1. å®Œå…¨é™æ€åºåˆ—: åºåˆ—ä¸­æ‰€æœ‰å¸§çš„å›¾åƒå®Œå…¨ç›¸åŒã€‚
2. å®Œå…¨éšæœºåºåˆ—: åºåˆ—ä¸­æ¯ä¸€å¸§çš„å›¾åƒéƒ½å®Œå…¨ä¸åŒã€‚
"""

import json
import numpy as np
from PIL import Image, ImageDraw, ImageEnhance
from pathlib import Path
import argparse
import logging
from datetime import datetime
from multiprocessing import Pool, cpu_count
from functools import partial

# ==================== æ—¥å¿—é…ç½® ====================
def setup_logger(log_file='pseudo_export.log'):
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # æ–‡ä»¶å¤„ç†å™¨
    fh = logging.FileHandler(log_file, encoding='utf-8')
    fh.setFormatter(formatter)
    if not logger.handlers:
        logger.addHandler(fh)
        # æ§åˆ¶å°å¤„ç†å™¨
        ch = logging.StreamHandler()
        ch.setFormatter(formatter)
        logger.addHandler(ch)

    return logger

LOGGER = setup_logger()

# ==================== å›¾åƒç”Ÿæˆæ ¸å¿ƒåŠŸèƒ½ ====================
def generate_random_image(config):
    """
    æ ¹æ®é…ç½®ç”Ÿæˆå•å¼ å®Œå…¨éšæœºçš„å›¾åƒ
    å¢å¼ºç‰ˆï¼šé¢œè‰²ã€å½¢æ€ã€èƒŒæ™¯ã€çº¹ç†å…¨éƒ¨éšæœºåŒ–
    """
    # 1. éšæœºå›¾åƒå°ºå¯¸
    base_size = config.get('base_size', [128, 128])
    size_variation = config.get('size_variation', 0.3)
    w = int(base_size[0] * (1 + np.random.uniform(-size_variation, size_variation)))
    h = int(base_size[1] * (1 + np.random.uniform(-size_variation, size_variation)))
    w, h = max(w, 32), max(h, 32)

    # 2. éšæœºèƒŒæ™¯ç±»å‹å’Œé¢œè‰²ï¼ˆå¢å¼ºéšæœºæ€§ï¼‰
    brightness_range = config.get('brightness_range', [30, 220])
    background_type = np.random.choice(['uniform', 'noise', 'gradient'])

    if background_type == 'uniform':
        # å‡åŒ€èƒŒæ™¯ï¼šéšæœºç°åº¦å€¼
        bg_color = np.random.randint(brightness_range[0], brightness_range[1])
        image_array = np.full((h, w), bg_color, dtype=np.uint8)
    elif background_type == 'noise':
        # å™ªå£°èƒŒæ™¯ï¼šæ¯ä¸ªåƒç´ éšæœº
        image_array = np.random.randint(brightness_range[0], brightness_range[1], (h, w), dtype=np.uint8)
    else:  # gradient
        # æ¸å˜èƒŒæ™¯ï¼šæ¨ªå‘æˆ–çºµå‘æ¸å˜
        direction = np.random.choice(['horizontal', 'vertical', 'diagonal'])
        start_color = np.random.randint(brightness_range[0], brightness_range[1])
        end_color = np.random.randint(brightness_range[0], brightness_range[1])

        if direction == 'horizontal':
            gradient = np.linspace(start_color, end_color, w, dtype=np.uint8)
            image_array = np.tile(gradient, (h, 1))
        elif direction == 'vertical':
            gradient = np.linspace(start_color, end_color, h, dtype=np.uint8)
            image_array = np.tile(gradient.reshape(-1, 1), (1, w))
        else:  # diagonal
            x_grad = np.linspace(0, 1, w)
            y_grad = np.linspace(0, 1, h)
            xx, yy = np.meshgrid(x_grad, y_grad)
            diag_grad = (xx + yy) / 2
            image_array = (start_color + (end_color - start_color) * diag_grad).astype(np.uint8)

    image = Image.fromarray(image_array, mode='L')

    # 3. éšæœºæ·»åŠ å½¢çŠ¶ï¼ˆå¢å¼ºå½¢æ€å’Œé¢œè‰²éšæœºæ€§ï¼‰
    if config.get('add_random_shapes', True):
        draw = ImageDraw.Draw(image)
        shape_types = config.get('shape_types', ['circle', 'ellipse', 'rectangle', 'polygon'])
        shapes_per_image = config.get('shapes_per_image', [1, 5])
        num_shapes = np.random.randint(shapes_per_image[0], shapes_per_image[1] + 1)

        for _ in range(num_shapes):
            shape_type = np.random.choice(shape_types)

            # éšæœºå½¢çŠ¶å¤§å°ï¼ˆæ›´å¤§çš„å˜åŒ–èŒƒå›´ï¼‰
            size_range = [int(min(w, h) * 0.05), int(min(w, h) * 0.5)]
            size = np.random.randint(size_range[0], max(size_range[0] + 1, size_range[1]))

            # éšæœºä½ç½®ï¼ˆç¡®ä¿ä¸è¶Šç•Œï¼‰
            margin = max(size, 5)
            if w > 2 * margin and h > 2 * margin:
                x = np.random.randint(margin, w - margin)
                y = np.random.randint(margin, h - margin)
            else:
                x, y = w // 2, h // 2

            # éšæœºé¢œè‰²ï¼ˆå…¨èŒƒå›´ï¼‰
            color = int(np.random.randint(0, 256))

            # éšæœºå½¢çŠ¶ç»˜åˆ¶
            if shape_type == 'circle':
                draw.ellipse([x - size, y - size, x + size, y + size], fill=color)

            elif shape_type == 'ellipse':
                # éšæœºæ¤­åœ†æ¯”ä¾‹
                size_w = int(size * np.random.uniform(0.3, 2.0))
                size_h = int(size * np.random.uniform(0.3, 2.0))
                # éšæœºæ—‹è½¬è§’åº¦ï¼ˆé€šè¿‡bboxå®ç°è¿‘ä¼¼æ—‹è½¬æ•ˆæœï¼‰
                draw.ellipse([x - size_w, y - size_h, x + size_w, y + size_h], fill=color)

            elif shape_type == 'rectangle':
                # éšæœºçŸ©å½¢æ¯”ä¾‹å’Œæ—‹è½¬
                size_w = int(size * np.random.uniform(0.3, 2.0))
                size_h = int(size * np.random.uniform(0.3, 2.0))
                draw.rectangle([x - size_w, y - size_h, x + size_w, y + size_h], fill=color)

            elif shape_type == 'polygon':
                # éšæœºå¤šè¾¹å½¢ï¼ˆä¸‰è§’å½¢åˆ°å…«è¾¹å½¢ï¼‰
                num_vertices = np.random.randint(3, 9)
                angles = np.sort(np.random.uniform(0, 2 * np.pi, num_vertices))
                radius = size * np.random.uniform(0.5, 1.5)
                vertices = [(x + int(radius * np.cos(a)), y + int(radius * np.sin(a))) for a in angles]
                draw.polygon(vertices, fill=color)

    # 4. éšæœºå›¾åƒåå¤„ç†ï¼ˆå¢å¼ºçº¹ç†å˜åŒ–ï¼‰
    # å¯¹æ¯”åº¦è°ƒæ•´
    contrast_variation = config.get('contrast_variation', 0.4)
    enhancer = ImageEnhance.Contrast(image)
    contrast_factor = 1.0 + np.random.uniform(-contrast_variation, contrast_variation)
    image = enhancer.enhance(contrast_factor)

    # éšæœºäº®åº¦è°ƒæ•´
    if np.random.random() > 0.5:
        brightness_enhancer = ImageEnhance.Brightness(image)
        brightness_factor = np.random.uniform(0.7, 1.3)
        image = brightness_enhancer.enhance(brightness_factor)

    # éšæœºé”åº¦è°ƒæ•´
    if np.random.random() > 0.5:
        sharpness_enhancer = ImageEnhance.Sharpness(image)
        sharpness_factor = np.random.uniform(0.5, 2.0)
        image = sharpness_enhancer.enhance(sharpness_factor)

    return image

# ==================== å¹¶è¡Œç”Ÿæˆè¾…åŠ©å‡½æ•° ====================
def generate_sequence_worker(args):
    """
    å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°ï¼Œç”¨äºå¹¶è¡Œç”Ÿæˆåºåˆ—
    """
    seq_id, category_id, category_name, seq_type, output_dir, config = args
    return generate_sequence(seq_id, category_id, category_name, seq_type, output_dir, config)

# ==================== åºåˆ—ç”Ÿæˆ ====================
def generate_sequence(seq_id, category_id, category_name, seq_type, output_dir, config):
    """
    ç”Ÿæˆä¸€ä¸ªæŒ‡å®šç±»å‹çš„ä¼ªåºåˆ—

    å‚æ•°:
        seq_id: åºåˆ—ç¼–å·
        category_id: ç±»åˆ«ID
        category_name: ç±»åˆ«åç§°
        seq_type: 'static' æˆ– 'random'
        output_dir: è¾“å‡ºç›®å½•
        config: ä»»åŠ¡é…ç½®
    """
    seq_length = config.get('sequence_length', 40)
    img_gen_config = config.get('image_generation', {})
    seq_folder = output_dir / 'images' / f"bbox_seq_{seq_id}"
    seq_folder.mkdir(parents=True, exist_ok=True)
    local_images = []

    if seq_type == 'static':
        # é™æ€åºåˆ—ï¼šåªç”Ÿæˆä¸€å¼ å›¾ï¼Œç„¶åå¤åˆ¶åˆ°æ‰€æœ‰å¸§
        static_image = generate_random_image(img_gen_config)
        for frame_idx in range(seq_length):
            img_path = seq_folder / f"{frame_idx}.png"
            static_image.save(img_path)
            local_images.append({
                'file_name': f"bbox_seq_{seq_id}/{frame_idx}.png",
                'time': frame_idx
            })
    elif seq_type == 'random':
        # éšæœºåºåˆ—ï¼šæ¯å¸§éƒ½é‡æ–°ç”Ÿæˆ
        for frame_idx in range(seq_length):
            random_image = generate_random_image(img_gen_config)
            img_path = seq_folder / f"{frame_idx}.png"
            random_image.save(img_path)
            local_images.append({
                'file_name': f"bbox_seq_{seq_id}/{frame_idx}.png",
                'time': frame_idx
            })

    local_annotations = {
        'bbox_seq_id': seq_id,
        'category_id': category_id,
        'category_name': category_name,
        'image_count': seq_length,
        'is_pseudo': True,
        'pseudo_type': seq_type
    }

    LOGGER.info(f"âœ… å·²ç”Ÿæˆ {seq_type} ä¼ªåºåˆ— bbox_seq_{seq_id} (ç±»åˆ«: {category_name})")
    return local_images, local_annotations

# ==================== ä¸»å‡½æ•° ====================
def main(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    output_dir = Path(config['output_directory'])
    (output_dir / 'images').mkdir(parents=True, exist_ok=True)
    (output_dir / 'annotations').mkdir(parents=True, exist_ok=True)

    anno_path = output_dir / 'annotations' / 'annotations.json'

    # ==================== å¢é‡åŠŸèƒ½ï¼šåŠ è½½å·²æœ‰æ•°æ® ====================
    all_images, all_annotations = [], []
    existing_categories = []
    image_id_counter, annotation_id_counter = 1, 1
    bbox_seq_counter = config.get('start_bbox_seq_id', 1)

    if anno_path.exists():
        LOGGER.info(f"ğŸ“‚ æ£€æµ‹åˆ°å·²æœ‰æ•°æ®é›†ï¼Œå¯ç”¨å¢é‡æ¨¡å¼")
        try:
            with open(anno_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)

            all_images = existing_data.get('images', [])
            all_annotations = existing_data.get('annotations', [])
            existing_categories = existing_data.get('categories', [])

            # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„ID
            if all_images:
                image_id_counter = max(img['id'] for img in all_images) + 1
            if all_annotations:
                annotation_id_counter = max(ann['id'] for ann in all_annotations) + 1
                # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„bbox_seq_id
                bbox_seq_ids = [ann.get('bbox_seq_id', 0) for ann in all_annotations]
                bbox_seq_counter = max(bbox_seq_ids) + 1 if bbox_seq_ids else bbox_seq_counter

            LOGGER.info(f"ğŸ“Š å·²åŠ è½½ç°æœ‰æ•°æ®ï¼š")
            LOGGER.info(f"   - ç°æœ‰åºåˆ—æ•°: {len(all_annotations)}")
            LOGGER.info(f"   - ç°æœ‰å›¾åƒæ•°: {len(all_images)}")
            LOGGER.info(f"   - ä¸‹ä¸€ä¸ªåºåˆ—ID: {bbox_seq_counter}")
            LOGGER.info(f"   - ä¸‹ä¸€ä¸ªå›¾åƒID: {image_id_counter}")
            LOGGER.info(f"   - ä¸‹ä¸€ä¸ªæ ‡æ³¨ID: {annotation_id_counter}")

        except Exception as e:
            LOGGER.warning(f"âš ï¸  åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°æ•°æ®é›†")
            all_images, all_annotations = [], []
            existing_categories = []
    else:
        LOGGER.info(f"ğŸ†• æœªæ£€æµ‹åˆ°å·²æœ‰æ•°æ®é›†ï¼Œåˆ›å»ºæ–°æ•°æ®é›†")

    # åˆå¹¶ç±»åˆ«ï¼ˆé¿å…é‡å¤ï¼‰
    category_map = {cat['name']: cat['id'] for cat in config.get('categories', [])}
    existing_cat_map = {cat['name']: cat for cat in existing_categories}

    for cat in config.get('categories', []):
        if cat['name'] not in existing_cat_map:
            existing_categories.append(cat)
            LOGGER.info(f"â• æ·»åŠ æ–°ç±»åˆ«: {cat['name']} (ID: {cat['id']})")

    LOGGER.info("ğŸš€ å¼€å§‹ç”Ÿæˆä¼ªåºåˆ—...")

    # è·å–CPUæ ¸å¿ƒæ•°ï¼Œç”¨äºå¹¶è¡Œå¤„ç†
    num_workers = min(cpu_count(), 8)  # æœ€å¤šä½¿ç”¨8ä¸ªè¿›ç¨‹
    use_parallel = config.get('use_parallel', True)  # é…ç½®é¡¹ï¼šæ˜¯å¦ä½¿ç”¨å¹¶è¡Œ

    if use_parallel and num_workers > 1:
        LOGGER.info(f"âš¡ å¯ç”¨å¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆï¼ˆ{num_workers} ä¸ªè¿›ç¨‹ï¼‰")
    else:
        LOGGER.info(f"ğŸ“ ä½¿ç”¨å•è¿›ç¨‹é¡ºåºç”Ÿæˆ")

    for task in config.get('generation_tasks', []):
        cat_name = task['category_name']
        if cat_name not in category_map:
            LOGGER.warning(f"âš ï¸  ç±»åˆ« '{cat_name}' æœªåœ¨é…ç½®ä¸­å®šä¹‰ï¼Œå·²è·³è¿‡")
            continue
        cat_id = category_map[cat_name]

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨ï¼ˆç”¨äºå¹¶è¡Œæˆ–é¡ºåºæ‰§è¡Œï¼‰
        tasks_to_generate = []

        # æ”¶é›†é™æ€åºåˆ—ä»»åŠ¡
        num_static = task.get('num_static_sequences', 0)
        if num_static > 0:
            LOGGER.info(f"ğŸ”¨ æ­£åœ¨ä¸ºç±»åˆ« '{cat_name}' ç”Ÿæˆ {num_static} ä¸ª 'static' åºåˆ—...")
            for _ in range(num_static):
                tasks_to_generate.append((
                    bbox_seq_counter, cat_id, cat_name, 'static', output_dir, task
                ))
                bbox_seq_counter += 1

        # æ”¶é›†éšæœºåºåˆ—ä»»åŠ¡
        num_random = task.get('num_random_sequences', 0)
        if num_random > 0:
            LOGGER.info(f"ğŸ”¨ æ­£åœ¨ä¸ºç±»åˆ« '{cat_name}' ç”Ÿæˆ {num_random} ä¸ª 'random' åºåˆ—...")
            for _ in range(num_random):
                tasks_to_generate.append((
                    bbox_seq_counter, cat_id, cat_name, 'random', output_dir, task
                ))
                bbox_seq_counter += 1

        # æ‰§è¡Œç”Ÿæˆï¼ˆå¹¶è¡Œæˆ–é¡ºåºï¼‰
        if use_parallel and num_workers > 1 and len(tasks_to_generate) > 1:
            # å¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆ
            with Pool(processes=num_workers) as pool:
                results = pool.map(generate_sequence_worker, tasks_to_generate)
        else:
            # å•è¿›ç¨‹é¡ºåºç”Ÿæˆ
            results = [generate_sequence_worker(task_args) for task_args in tasks_to_generate]

        # å¤„ç†ç»“æœï¼Œåˆ†é…ID
        for images, annotation in results:
            first_img_id = image_id_counter
            for img in images:
                img['id'] = image_id_counter
                all_images.append(img)
                image_id_counter += 1
            annotation['id'] = annotation_id_counter
            annotation['image_id'] = first_img_id
            all_annotations.append(annotation)
            annotation_id_counter += 1

    # ä¿å­˜annotations.json
    final_data = {
        "info": {
            "description": "ä¼ªåºåˆ—æ•°æ®é›†ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰",
            "year": datetime.now().year,
            "last_updated": datetime.now().isoformat()
        },
        "images": all_images,
        "annotations": all_annotations,
        "categories": existing_categories
    }
    anno_path = output_dir / 'annotations' / 'annotations.json'
    with open(anno_path, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    LOGGER.info(f"ğŸ‰ ä¼ªåºåˆ—ç”Ÿæˆå®Œæˆï¼")
    LOGGER.info(f"ğŸ“‚ æ•°æ®é›†ä¿å­˜åˆ°: {output_dir}")
    LOGGER.info(f"ğŸ“ æ ‡æ³¨æ–‡ä»¶: {anno_path}")
    LOGGER.info(f"ğŸ“Š æ€»è®¡ç”Ÿæˆ: {len(all_annotations)} ä¸ªåºåˆ—, {len(all_images)} å¼ å›¾åƒ")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç‹¬ç«‹çš„ä¼ªåºåˆ—ç”Ÿæˆå·¥å…·")
    parser.add_argument(
        '--config',
        type=str,
        default='pseudo_generator_config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    args = parser.parse_args()
    main(args.config)

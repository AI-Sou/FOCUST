# -*- coding: utf-8 -*-
import json
import re
import os
import shutil
from pathlib import Path
from PIL import Image, UnidentifiedImageError
import logging
from collections import OrderedDict
import multiprocessing
import argparse
from datetime import datetime
import numpy as np

# ==================== ç¿»è¯‘å­—å…¸ï¼ˆæ”¯æŒä¸­è‹±ï¼‰ ====================
TRANSLATIONS = {
    'zh_CN': {
        'info_prepare_export_classification_dataset': 'å‡†å¤‡å¯¼å‡ºåˆ†ç±»æ•°æ®é›†...',
        'info_incremental_export_mode': 'æ£€æµ‹åˆ°ç°æœ‰æ•°æ®é›†ï¼Œå°†ä» bbox_seq_{0} å¼€å§‹å¢é‡å¯¼å‡ºã€‚',
        'info_debug_mode_activated': "Debugæ¨¡å¼å·²æ¿€æ´»ï¼Œå°†å¤åˆ¶æœ¬æ¬¡å¯¼å‡ºçš„å‰10ä¸ªæ ·æœ¬åˆ° 'debug' æ–‡ä»¶å¤¹ã€‚",
        'info_skipping_completed_sequence': "è·³è¿‡å·²å®Œæˆçš„æºåºåˆ— {0}...",
        'warning_load_existing_failed': 'è­¦å‘Š: è¯»å–ç°æœ‰ annotations.json å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°çš„æ–‡ä»¶ã€‚é”™è¯¯: {0}',
        'warning_sequence_id_not_found': 'åºåˆ—ID {0} æœªæ‰¾åˆ°ã€‚',
        'warning_no_images_in_current_sequence': 'åºåˆ— {0} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼Œå·²è·³è¿‡ã€‚',
        'warning_invalid_bbox_skipped': "è­¦å‘Š: åœ¨åºåˆ— {0} çš„å¸§ {1} ä¸­å‘ç°æ— æ•ˆBBox {2} (æ ‡å‡†åŒ–åå°ºå¯¸ä¸ºé›¶æˆ–åœ¨å›¾åƒå¤–)ï¼Œå·²è·³è¿‡è¯¥æ ‡æ³¨ã€‚",
        'dataset_description_classification': 'åˆ†ç±»æ•°æ®é›†ï¼Œç”±æ£€æµ‹æ•°æ®é›†å¯¼å‡º',
        'info_saving_annotations_json_file': 'æ­£åœ¨ä¿å­˜ annotations.json æ–‡ä»¶...',
        'info_classification_dataset_exported': 'åˆ†ç±»æ•°æ®é›†å¯¼å‡ºå®Œæˆã€‚',
        'info_export_success_path': 'æˆåŠŸå¯¼å‡ºåˆ°: {0}',
        'error_detection_dataset_path_invalid': 'é”™è¯¯: æ£€æµ‹æ•°æ®é›†è·¯å¾„æ— æ•ˆ: {0}',
        'error_annotations_file_not_found': 'é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨äº {0}',
        'error_create_export_folder': 'é”™è¯¯: æ— æ³•åˆ›å»ºå¯¼å‡ºæ–‡ä»¶å¤¹ {0}: {1}',
        'error_no_sequence_loaded': 'é”™è¯¯: æœªåŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆçš„åºåˆ—ã€‚',
        'error_export_classification_failed': 'å¯¼å‡ºåˆ†ç±»æ•°æ®é›†å¤±è´¥: {0}',
        'info_annotations_only_mode': 'å·²æ¿€æ´»â€œä»…ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶â€æ¨¡å¼ï¼Œå°†è·³è¿‡å›¾åƒè£åˆ‡ã€‚',
        'warning_process_frame_failed': 'è­¦å‘Š: å¤„ç†åºåˆ— {0} çš„å¸§ {1} æ—¶å‡ºé”™ï¼Œå·²è·³è¿‡æ­¤å¸§ã€‚é”™è¯¯: {2}',
        'warning_get_time_from_json_failed': 'æ— æ³•ä»annotations.jsonè·å–timeä¿¡æ¯ï¼Œå°†å›é€€: {0}',
        'warning_match_images2_failed': 'æŒ‰æ–‡ä»¶åç²¾ç¡®åŒ¹é…images2å¤±è´¥: {0}ï¼Œå°†ä½¿ç”¨å›é€€ç­–ç•¥ã€‚',
        'warning_annotation_dropped_no_image': 'è­¦å‘Š: æ— æ³•ä¸º bbox_seq {0} æ‰¾åˆ°å¯¹åº”çš„é¦–å¸§å›¾åƒï¼Œè¯¥æ ‡æ³¨å°†è¢«ä¸¢å¼ƒã€‚',
    },
    'en': {
        'info_prepare_export_classification_dataset': 'Preparing to export classification dataset...',
        'info_incremental_export_mode': 'Existing dataset detected. Starting incremental export from bbox_seq_{0}.',
        'info_debug_mode_activated': "Debug mode activated. The first 10 samples from this run will be copied to the 'debug' folder.",
        'info_skipping_completed_sequence': "Skipping already completed source sequence {0}...",
        'warning_load_existing_failed': 'Warning: Failed to read existing annotations.json, a new file will be created. Error: {0}',
        'warning_sequence_id_not_found': 'Sequence ID {0} not found.',
        'warning_no_images_in_current_sequence': 'No image files found in sequence {0}, skipped.',
        'warning_invalid_bbox_skipped': "Warning: Invalid BBox {2} found in sequence {0}, frame {1} (zero size or outside image after normalization), skipping this annotation.",
        'dataset_description_classification': 'Classification dataset exported from detection dataset',
        'info_saving_annotations_json_file': 'Saving annotations.json file...',
        'info_classification_dataset_exported': 'Classification dataset exported successfully.',
        'info_export_success_path': 'Successfully exported to: {0}',
        'error_detection_dataset_path_invalid': 'Error: Invalid detection dataset path: {0}',
        'error_annotations_file_not_found': 'Error: Annotations file not found at {0}',
        'error_create_export_folder': 'Error: Failed to create export folder {0}: {1}',
        'error_no_sequence_loaded': 'Error: No valid sequences were loaded.',
        'error_export_classification_failed': 'Failed to export classification dataset: {0}',
        'info_annotations_only_mode': 'Annotations-only mode activated, skipping image cropping.',
        'warning_process_frame_failed': 'Warning: Error processing frame {1} in sequence {0}, skipping this frame. Error: {2}',
        'warning_get_time_from_json_failed': 'Could not get time info from annotations.json, falling back: {0}',
        'warning_match_images2_failed': 'Exact filename matching for images2 failed: {0}, using fallback strategy.',
        'warning_annotation_dropped_no_image': 'Warning: Could not find a corresponding first-frame image for bbox_seq {0}, this annotation will be dropped.',
    }
}

def get_translation(language='zh_CN'):
    """è·å–æŒ‡å®šè¯­è¨€çš„ç¿»è¯‘å­—å…¸"""
    return TRANSLATIONS.get(language, TRANSLATIONS['zh_CN'])

# ==================== é…ç½®æ–‡ä»¶åŠ è½½ ====================
def load_config(config_path='auto_biocate1_config.json'):
    """
    åŠ è½½é…ç½®æ–‡ä»¶

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        dict: é…ç½®å­—å…¸ï¼Œå¦‚æœåŠ è½½å¤±è´¥åˆ™è¿”å›é»˜è®¤é…ç½®
    """
    default_config = {
        "export_settings": {
            "enable_bbox_expansion": False,
            "bbox_expansion_config": {
                "expansion_mode": "dynamic",
                "expansion_ratio": 0.2,
                "min_expansion_pixels": 10,
                "max_expansion_pixels": 50,
                "check_overlap": True,
                "overlap_threshold": 0.0
            },
            "enable_category_limit": False,
            "category_limit_config": {
                "per_category_limit": 100,
                "stop_when_limit_reached": True
            }
        }
    }

    # å°è¯•ä»è„šæœ¬åŒç›®å½•åŠ è½½é…ç½®
    script_dir = Path(__file__).parent
    config_file = script_dir / config_path

    if not config_file.exists():
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config

    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        return config
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config

# ==================== è¾¹ç•Œæ¡†æ‰©å¼ åŠŸèƒ½ ====================
def calculate_iou(box1, box2):
    """
    è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU (Intersection over Union)

    Args:
        box1, box2: (x1, y1, x2, y2) æ ¼å¼çš„è¾¹ç•Œæ¡†

    Returns:
        float: IoUå€¼
    """
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])

    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return 0.0

    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union_area = box1_area + box2_area - inter_area

    return inter_area / union_area if union_area > 0 else 0.0

def expand_bbox(bbox, all_bboxes, img_width, img_height, expansion_config):
    """
    æ ¹æ®é…ç½®åŠ¨æ€æ‰©å¼ è¾¹ç•Œæ¡†ï¼Œé¿å…ä¸å…¶ä»–æ¡†é‡å 

    Args:
        bbox: å½“å‰è¦æ‰©å¼ çš„è¾¹ç•Œæ¡† [x, y, w, h]
        all_bboxes: åŒä¸€å¸§ä¸­çš„æ‰€æœ‰å…¶ä»–è¾¹ç•Œæ¡†åˆ—è¡¨
        img_width, img_height: å›¾åƒå°ºå¯¸
        expansion_config: æ‰©å¼ é…ç½®å­—å…¸

    Returns:
        tuple: (æ‰©å¼ åçš„x1, y1, x2, y2)
    """
    x, y, w, h = bbox
    x1, y1 = x, y
    x2, y2 = x + w, y + h

    # å¦‚æœæœªå¯ç”¨æ‰©å¼ ï¼Œç›´æ¥è¿”å›åŸæ¡†
    if not expansion_config:
        return (x1, y1, x2, y2)

    expansion_mode = expansion_config.get('expansion_mode', 'dynamic')
    expansion_ratio = expansion_config.get('expansion_ratio', 0.2)
    min_pixels = expansion_config.get('min_expansion_pixels', 10)
    max_pixels = expansion_config.get('max_expansion_pixels', 50)
    check_overlap = expansion_config.get('check_overlap', True)
    overlap_threshold = expansion_config.get('overlap_threshold', 0.0)

    # è®¡ç®—åˆå§‹æ‰©å¼ é‡
    if expansion_mode == 'dynamic':
        # åŠ¨æ€æ¨¡å¼ï¼šåŸºäºæ¡†å¤§å°çš„æ¯”ä¾‹
        expand_w = max(min_pixels, min(max_pixels, w * expansion_ratio))
        expand_h = max(min_pixels, min(max_pixels, h * expansion_ratio))
    else:
        # å›ºå®šæ¨¡å¼ï¼šä½¿ç”¨å›ºå®šåƒç´ 
        expand_w = expand_h = (min_pixels + max_pixels) / 2

    # åˆå§‹æ‰©å¼ 
    expanded_x1 = max(0, x1 - expand_w)
    expanded_y1 = max(0, y1 - expand_h)
    expanded_x2 = min(img_width, x2 + expand_w)
    expanded_y2 = min(img_height, y2 + expand_h)

    # å¦‚æœéœ€è¦æ£€æŸ¥é‡å 
    if check_overlap and all_bboxes:
        # è½¬æ¢å…¶ä»–æ¡†ä¸º (x1, y1, x2, y2) æ ¼å¼
        other_boxes = []
        for other_bbox in all_bboxes:
            if other_bbox == bbox:  # è·³è¿‡è‡ªå·±
                continue
            ox, oy, ow, oh = other_bbox
            other_boxes.append((ox, oy, ox + ow, oy + oh))

        # é€æ­¥ç¼©å°æ‰©å¼ ï¼Œç›´åˆ°ä¸é‡å æˆ–è¾¾åˆ°æœ€å°æ‰©å¼ 
        while expand_w > min_pixels or expand_h > min_pixels:
            expanded_box = (expanded_x1, expanded_y1, expanded_x2, expanded_y2)

            # æ£€æŸ¥æ˜¯å¦ä¸ä»»ä½•å…¶ä»–æ¡†é‡å 
            has_overlap = False
            for other_box in other_boxes:
                iou = calculate_iou(expanded_box, other_box)
                if iou > overlap_threshold:
                    has_overlap = True
                    break

            if not has_overlap:
                break

            # ç¼©å°æ‰©å¼ 
            expand_w = max(min_pixels, expand_w * 0.8)
            expand_h = max(min_pixels, expand_h * 0.8)
            expanded_x1 = max(0, x1 - expand_w)
            expanded_y1 = max(0, y1 - expand_h)
            expanded_x2 = min(img_width, x2 + expand_w)
            expanded_y2 = min(img_height, y2 + expand_h)

    return (int(expanded_x1), int(expanded_y1), int(expanded_x2), int(expanded_y2))


# ==================== æ—¥å¿—é…ç½® ====================
def setup_logger(log_file='export.log', level=logging.INFO):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨ï¼Œæ”¯æŒå¤šè¿›ç¨‹"""
    logger = multiprocessing.get_logger()
    if logger.hasHandlers():
        logger.handlers.clear()
        
    logger.setLevel(level)
    formatter = logging.Formatter('%(asctime)s - %(processName)s - %(levelname)s - %(message)s')
    
    fh = logging.FileHandler(log_file, encoding='utf-8')
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    
    ch = logging.StreamHandler()
    ch.setFormatter(formatter)
    logger.addHandler(ch)
        
    return logger

# ==================== è¾…åŠ©å‡½æ•° (ä¸ç¼–è¾‘å™¨é€»è¾‘å®Œå…¨ä¸€è‡´) ====================
def get_seq_images_with_time(seq_id, seq_dir_path, base_folder, logger, translation):
    """
    è·å–åºåˆ—çš„æ‰€æœ‰å›¾åƒå¹¶æŒ‰æ—¶é—´æ’åºï¼Œè¿”å›(å›¾åƒè·¯å¾„, time)å…ƒç»„åˆ—è¡¨ã€‚
    """
    seq_dir = Path(seq_dir_path)
    all_images = [p for p in seq_dir.iterdir() if p.suffix.lower() in ['.jpg', '.jpeg', '.png']]
    images_with_time = []
    
    if images_data:
        try:
            path_to_time = {}
            for img_info in images_data:
                if img_info.get('sequence_id') == seq_id:
                    img_path = base_folder / img_info.get('file_name', '')
                    if img_path.exists():
                        time_val = img_info.get('time', 0)
                        if isinstance(time_val, str) and time_val.isdigit():
                            time_val = int(time_val)
                        path_to_time[str(img_path)] = time_val
            
            for img_path in all_images:
                str_path = str(img_path)
                if str_path in path_to_time:
                    images_with_time.append((img_path, path_to_time[str_path]))
                else:
                    match = re.search(r'(\d+)', img_path.name)
                    time_val = int(match.group(1)) if match else os.path.getmtime(img_path)
                    images_with_time.append((img_path, time_val))
        except Exception as e:
            logger.warning(translation['warning_get_time_from_json_failed'].format(e))
            images_with_time.clear()

    if not images_with_time:
        for img_path in all_images:
            match = re.search(r'(\d+)', img_path.name)
            time_val = int(match.group(1)) if match else os.path.getmtime(img_path)
            images_with_time.append((img_path, time_val))
    
    return sorted(images_with_time, key=lambda x: x[1])

def get_matching_images2_with_time(seq_dir2_path, original_images_with_time, logger, translation):
    """
    è·å–ä¸åŸå§‹å›¾åƒç›¸åŒé¡ºåºçš„images2æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒã€‚
    """
    seq_dir2 = Path(seq_dir2_path)
    if not seq_dir2.exists():
        return []
        
    all_images2 = [p for p in seq_dir2.iterdir() if p.suffix.lower() in ['.jpg', '.jpeg', '.png']]
    
    if len(all_images2) == len(original_images_with_time):
        try:
            name_to_path = {img.name: img for img in all_images2}
            result = []
            all_matched = True
            for orig_img, time_val in original_images_with_time:
                if orig_img.name in name_to_path:
                    result.append((name_to_path[orig_img.name], time_val))
                else:
                    all_matched = False
                    break
            if all_matched:
                return result
        except Exception as e:
            logger.warning(translation['warning_match_images2_failed'].format(e))
            
    sorted_images2 = sorted(all_images2, key=lambda x: os.path.getmtime(str(x)))
    result = []
    len_orig = len(original_images_with_time)
    len_img2 = len(sorted_images2)
    
    for i, (_, time_val) in enumerate(original_images_with_time):
        if i < len_img2:
            result.append((sorted_images2[i], time_val))
        elif sorted_images2:
            result.append((sorted_images2[-1], time_val))
            
    return result

# ==================== æ ¸å¿ƒå¯¼å‡ºå‡½æ•°ï¼ˆæ¯ä¸ªè¿›ç¨‹å¤„ç†ä¸€ä¸ªåºåˆ—ï¼‰ ====================
def process_sequence(args):
    """
    åœ¨å¤šè¿›ç¨‹ä¸­å¤„ç†å•ä¸ªåºåˆ—çš„è£å‰ªå’Œæ ‡æ³¨ç”Ÿæˆã€‚
    æ”¯æŒè¾¹ç•Œæ¡†æ‰©å¼ å’Œç±»åˆ«é™åˆ¶åŠŸèƒ½ã€‚
    """
    (seq, base_folder, output_dir, has_images2, start_bbox_seq,
     annotations_only, language, debug, initial_bbox_seq_counter,
     config, category_counter) = args
    
    logger = multiprocessing.get_logger()
    translation = get_translation(language)

    seq_id = seq['sequence_id']
    last_img_path_str = seq['last_image_path']
    anns = annotations_data.get(seq_id, {}).get(last_img_path_str, [])
    
    if not anns:
        logger.info(f"åºåˆ— {seq_id} åœ¨æœ€åä¸€å¼ å›¾åƒä¸Šæ²¡æœ‰æ ‡æ³¨ï¼Œå·²è·³è¿‡ã€‚")
        return [], [], 0
    
    logger.info(f"æ­£åœ¨å¤„ç†åºåˆ— {seq_id}...")
    
    image_files_with_time = get_seq_images_with_time(seq_id, seq['image_dir'], base_folder, logger, translation)
    if not image_files_with_time:
        logger.warning(translation['warning_no_images_in_current_sequence'].format(seq_id))
        return [], [], 0
        
    image_files2_with_time = []
    if has_images2 and 'image_dir2' in seq:
        image_files2_with_time = get_matching_images2_with_time(seq['image_dir2'], image_files_with_time, logger, translation)

    images_dir = output_dir / 'images'
    images2_dir = output_dir / 'images2' if has_images2 else None

    local_images = []
    local_annotations = []
    created_ann_for_seq = set()

    # è·å–é…ç½®
    export_settings = config.get('export_settings', {})
    enable_bbox_expansion = export_settings.get('enable_bbox_expansion', False)
    bbox_expansion_config = export_settings.get('bbox_expansion_config', {}) if enable_bbox_expansion else None
    enable_category_limit = export_settings.get('enable_category_limit', False)
    category_limit_config = export_settings.get('category_limit_config', {})

    # å‡†å¤‡æ‰€æœ‰æ ‡æ³¨æ¡†åˆ—è¡¨ï¼ˆç”¨äºé‡å æ£€æµ‹ï¼‰
    all_bboxes_in_frame = [ann['bbox'] for ann in anns]

    if not annotations_only:
        for i in range(len(anns)):
            bbox_seq_num = start_bbox_seq + i
            (images_dir / f"bbox_seq_{bbox_seq_num}").mkdir(exist_ok=True)
            if images2_dir:
                (images2_dir / f"bbox_seq_{bbox_seq_num}").mkdir(exist_ok=True)

    for frame_idx, (img_file, time_val) in enumerate(image_files_with_time):
        try:
            with Image.open(img_file) as img1:
                img1_size = img1.size

                img2, img2_size = None, None
                if frame_idx < len(image_files2_with_time):
                    img2_file, _ = image_files2_with_time[frame_idx]
                    img2 = Image.open(img2_file)
                    img2_size = img2.size

                for ann_idx, ann in enumerate(anns):
                    category_id = ann.get('category_id')

                    # ã€æ–°åŠŸèƒ½ã€‘æ£€æŸ¥ç±»åˆ«é™åˆ¶ï¼ˆç»Ÿä¸€é™åˆ¶ï¼‰
                    if enable_category_limit:
                        # è·å–ç±»åˆ«åç§°
                        category_name = None
                        for cat in categories_data:
                            if cat['id'] == category_id:
                                category_name = cat['name']
                                break

                        if category_name:
                            # è·å–ç»Ÿä¸€çš„ç±»åˆ«é™åˆ¶
                            per_category_limit = category_limit_config.get('per_category_limit', 100)
                            current_count = category_counter.get(category_name, 0)

                            # æ£€æŸ¥è¯¥ç±»åˆ«æ˜¯å¦å·²è¾¾åˆ°é™åˆ¶
                            if current_count >= per_category_limit:
                                logger.info(f"â¸ï¸  ç±»åˆ« '{category_name}' å·²è¾¾åˆ°å¯¼å‡ºé™åˆ¶ ({per_category_limit})ï¼Œè·³è¿‡")
                                continue

                    x, y, w, h = ann['bbox']

                    ## BUG FIX: æ ‡å‡†åŒ–BBoxåæ ‡ï¼Œé˜²æ­¢å› è´Ÿå®½åº¦/é«˜åº¦å¯¼è‡´cropå¤±è´¥
                    x_min = min(x, x + w)
                    y_min = min(y, y + h)
                    x_max = max(x, x + w)
                    y_max = max(y, y + h)

                    # ã€æ–°åŠŸèƒ½ã€‘è¾¹ç•Œæ¡†æ‰©å¼ 
                    if enable_bbox_expansion and bbox_expansion_config:
                        expanded_box = expand_bbox(
                            [x, y, w, h],
                            all_bboxes_in_frame,
                            img1_size[0], img1_size[1],
                            bbox_expansion_config
                        )
                        crop_left, crop_upper, crop_right, crop_lower = expanded_box
                        logger.debug(f"ğŸ“ æ‰©å¼ è¾¹ç•Œæ¡†: åŸå§‹ ({x_min},{y_min},{x_max},{y_max}) -> æ‰©å¼ å ({crop_left},{crop_upper},{crop_right},{crop_lower})")
                    else:
                        # ä½¿ç”¨åŸå§‹è¾¹ç•Œæ¡†
                        crop_left = max(0, x_min)
                        crop_upper = max(0, y_min)
                        crop_right = min(img1_size[0], x_max)
                        crop_lower = min(img1_size[1], y_max)

                    # ç¡®ä¿è£å‰ªæ¡†åœ¨å›¾åƒè¾¹ç•Œå†…
                    crop_left = max(0, crop_left)
                    crop_upper = max(0, crop_upper)
                    crop_right = min(img1_size[0], crop_right)
                    crop_lower = min(img1_size[1], crop_lower)

                    # å¦‚æœæ ‡å‡†åŒ–åçš„æ¡†å°ºå¯¸ä¸º0æˆ–æ— æ•ˆï¼Œåˆ™è·³è¿‡
                    if crop_right <= crop_left or crop_lower <= crop_upper:
                        logger.warning(translation['warning_invalid_bbox_skipped'].format(seq_id, img_file.name, ann['bbox']))
                        continue
                    ## END BUG FIX

                    bbox_seq_num = start_bbox_seq + ann_idx
                    
                    if not annotations_only:
                        crop_box1 = (crop_left, crop_upper, crop_right, crop_lower)
                        out_path1 = images_dir / f"bbox_seq_{bbox_seq_num}" / f"{time_val}.png"
                        cropped1 = img1.crop(crop_box1)
                        cropped1.save(out_path1, "PNG")

                        if debug and bbox_seq_num < initial_bbox_seq_counter + 10:
                            debug_seq_dir = output_dir / 'debug' / 'images' / f"bbox_seq_{bbox_seq_num}"
                            debug_seq_dir.mkdir(parents=True, exist_ok=True)
                            shutil.copy(out_path1, debug_seq_dir)

                        if img2 and img2_size:
                            crop_box2 = (max(0, x_min), max(0, y_min), min(img2_size[0], x_max), min(img2_size[1], y_max))
                            if crop_box2[2] > crop_box2[0] and crop_box2[3] > crop_box2[1]:
                                out_path2 = images2_dir / f"bbox_seq_{bbox_seq_num}" / f"{time_val}.png"
                                cropped2 = img2.crop(crop_box2)
                                cropped2.save(out_path2, "PNG")

                                if debug and bbox_seq_num < initial_bbox_seq_counter + 10:
                                    debug_seq2_dir = output_dir / 'debug' / 'images2' / f"bbox_seq_{bbox_seq_num}"
                                    debug_seq2_dir.mkdir(parents=True, exist_ok=True)
                                    shutil.copy(out_path2, debug_seq2_dir)

                    rel_path = f"images/bbox_seq_{bbox_seq_num}/{time_val}.png"
                    # ä½¿ç”¨æ ‡å‡†åŒ–åçš„å°ºå¯¸
                    width, height = (crop_right - crop_left), (crop_lower - crop_upper)
                    
                    new_image_entry = {"id": 0, "file_name": rel_path, "sequence_id": bbox_seq_num, "width": width, "height": height, "time": str(time_val)}
                    local_images.append(new_image_entry)
                    
                    if bbox_seq_num not in created_ann_for_seq:
                        category_id = ann.get('category_id')
                        new_ann_entry = {
                            "id": 0, "image_id": bbox_seq_num, "sequence_id": bbox_seq_num,
                            "category_id": category_id, "bbox": ann['bbox'],
                            "area": float(abs(w * h)), "iscrowd": 0, "scale": len(image_files_with_time),
                            "source_sequence_id": seq_id  # ## NEW FEATURE: è®°å½•æ¥æºåºåˆ—IDï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ 
                        }
                        local_annotations.append(new_ann_entry)
                        created_ann_for_seq.add(bbox_seq_num)

                        # ã€æ–°åŠŸèƒ½ã€‘æ›´æ–°ç±»åˆ«è®¡æ•°å™¨
                        if enable_category_limit and category_name:
                            category_counter[category_name] = category_counter.get(category_name, 0) + 1
                            logger.debug(f"ğŸ“Š ç±»åˆ« '{category_name}' è®¡æ•°: {category_counter[category_name]}/{per_category_limit}")
                
                if img2:
                    img2.close()
        except (IOError, UnidentifiedImageError, OSError) as e:
            logger.warning(translation['warning_process_frame_failed'].format(seq_id, img_file.name, e))
            continue
            
    return local_images, local_annotations, len(anns)

# ==================== åˆå§‹åŒ–å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹ ====================
def init_worker(ann_data, cats_data, imgs_data):
    """åˆå§‹åŒ–æ¯ä¸ªå·¥ä½œè¿›ç¨‹çš„å…¨å±€å˜é‡"""
    global annotations_data, categories_data, images_data
    annotations_data = ann_data
    categories_data = cats_data
    images_data = imgs_data

# ==================== ä¸»å¯¼å‡ºå‡½æ•° ====================
def export_classification_dataset(detection_dir, export_dir, num_cores, language='zh_CN', annotations_only=False, debug=False, config_path='auto_biocate1_config.json'):
    """
    ä¸»å‡½æ•°ï¼šä»æ£€æµ‹æ•°æ®é›†å¯¼å‡ºåˆ†ç±»æ•°æ®é›†
    æ”¯æŒå¢é‡å¯¼å‡ºã€å¤šè¿›ç¨‹ã€debugæ¨¡å¼ã€è¾¹ç•Œæ¡†æ‰©å¼ å’Œç±»åˆ«é™åˆ¶

    Args:
        detection_dir: æ£€æµ‹æ•°æ®é›†è·¯å¾„
        export_dir: å¯¼å‡ºè·¯å¾„
        num_cores: CPUæ ¸å¿ƒæ•°
        language: è¯­è¨€ ('zh_CN' æˆ– 'en')
        annotations_only: æ˜¯å¦ä»…ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    output_path = Path(export_dir)
    translation = get_translation(language)
    logger = setup_logger(log_file=output_path / 'export.log')

    # ã€æ–°åŠŸèƒ½ã€‘åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config(config_path)
    logger.info(f"ğŸ“„ é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ")

    # æ˜¾ç¤ºå¯ç”¨çš„åŠŸèƒ½
    export_settings = config.get('export_settings', {})
    if export_settings.get('enable_bbox_expansion'):
        logger.info("âœ… è¾¹ç•Œæ¡†æ‰©å¼ åŠŸèƒ½å·²å¯ç”¨")
    if export_settings.get('enable_category_limit'):
        logger.info("âœ… ç±»åˆ«é™åˆ¶åŠŸèƒ½å·²å¯ç”¨")

    if annotations_only:
        logger.info(translation['info_annotations_only_mode'])

    base_folder = Path(detection_dir)
    if not base_folder.exists() or not base_folder.is_dir():
        logger.error(translation['error_detection_dataset_path_invalid'].format(detection_dir))
        return
    
    try:
        output_path.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        logger.error(translation['error_create_export_folder'].format(export_dir, e))
        return
    
    annotations_file = base_folder / 'annotations' / 'annotations.json'
    if not annotations_file.exists():
        logger.error(translation['error_annotations_file_not_found'].format(annotations_file))
        return
    
    with open(annotations_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    global categories_data, annotations_data, images_data
    categories_data = data.get('categories', [])
    images_data = data.get('images', [])
    annotations_data = {}
    
    all_images_list = []
    all_annotations_list = []
    image_id_counter = 1
    annotation_id_counter = 1
    bbox_seq_counter = 1
    completed_source_seq_ids = set() # ## NEW FEATURE: ç”¨äºå­˜å‚¨å·²å®Œæˆçš„æºåºåˆ—ID

    export_annotations_file = output_path / 'annotations' / 'annotations.json'
    if export_annotations_file.exists():
        try:
            with open(export_annotations_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            all_images_list = existing_data.get('images', [])
            all_annotations_list = existing_data.get('annotations', [])
            
            existing_cat_names = {cat['name'] for cat in categories_data}
            for cat in existing_data.get('categories', []):
                if cat['name'] not in existing_cat_names:
                    categories_data.append(cat)
                    existing_cat_names.add(cat['name'])
            
            if all_images_list:
                image_id_counter = max(img['id'] for img in all_images_list) + 1
            if all_annotations_list:
                annotation_id_counter = max(ann['id'] for ann in all_annotations_list) + 1
                # ## NEW FEATURE: æ„å»ºå·²å®Œæˆçš„æºåºåˆ—IDé›†åˆ
                for ann in all_annotations_list:
                    if 'source_sequence_id' in ann:
                        completed_source_seq_ids.add(ann['source_sequence_id'])
            
            export_images_dir = output_path / 'images'
            if export_images_dir.exists():
                seq_nums = [int(p.name.split('_')[-1]) for p in export_images_dir.glob('bbox_seq_*') if p.name.split('_')[-1].isdigit()]
                if seq_nums:
                    bbox_seq_counter = max(seq_nums) + 1
            
            logger.info(translation['info_incremental_export_mode'].format(bbox_seq_counter))
        except Exception as e:
            logger.warning(translation['warning_load_existing_failed'].format(e))
    
    initial_bbox_seq_counter = bbox_seq_counter
    
    img_id_to_seq_id = {img['id']: img['sequence_id'] for img in images_data}
    seq_id_to_last_img_path = {}

    for seq_id in {img['sequence_id'] for img in images_data}:
        seq_images = [img for img in images_data if img.get('sequence_id') == seq_id]
        if seq_images:
            last_image = sorted(seq_images, key=lambda i: int(i.get('time', 0)))[-1]
            seq_id_to_last_img_path[seq_id] = str((base_folder / last_image['file_name']).resolve())

    for ann in data.get('annotations', []):
        img_id = ann.get('image_id')
        seq_id = img_id_to_seq_id.get(img_id)
        if not seq_id: continue
        
        last_img_path = seq_id_to_last_img_path.get(seq_id)
        if not last_img_path: continue

        current_img_path = str((base_folder / next(i['file_name'] for i in images_data if i['id'] == img_id)).resolve())
        if current_img_path == last_img_path:
            if seq_id not in annotations_data:
                annotations_data[seq_id] = {last_img_path: []}
            annotations_data[seq_id][last_img_path].append(ann)

    sequences = []
    images_dir = base_folder / 'images'
    images2_dir = base_folder / 'images2'
    has_images2 = images2_dir.exists()
    for seq_folder in sorted([f for f in images_dir.iterdir() if f.is_dir() and f.name.isdigit()], key=lambda x: int(x.name)):
        seq_id = int(seq_folder.name)
        if seq_id_to_last_img_path.get(seq_id):
            seq_dict = {
                "sequence_id": seq_id, 
                "image_dir": str(seq_folder), 
                "last_image_path": seq_id_to_last_img_path[seq_id]
            }
            if has_images2 and (images2_dir / seq_folder.name).exists():
                seq_dict["image_dir2"] = str(images2_dir / seq_folder.name)
            sequences.append(seq_dict)

    if not sequences:
        logger.error(translation['error_no_sequence_loaded'])
        return
    
    logger.info(translation['info_prepare_export_classification_dataset'])
    
    (output_path / 'annotations').mkdir(exist_ok=True)
    if not annotations_only:
        (output_path / 'images').mkdir(exist_ok=True)
        if has_images2:
            (output_path / 'images2').mkdir(exist_ok=True)
    
    if debug and not annotations_only:
        logger.info(translation['info_debug_mode_activated'])
        debug_dir = output_path / 'debug'
        (debug_dir / 'images').mkdir(parents=True, exist_ok=True)
        if has_images2:
            (debug_dir / 'images2').mkdir(parents=True, exist_ok=True)

    # ã€æ–°åŠŸèƒ½ã€‘åˆå§‹åŒ–ç±»åˆ«è®¡æ•°å™¨ï¼ˆç”¨äºé™åˆ¶å¯¼å‡ºæ•°é‡ï¼‰
    from multiprocessing import Manager
    manager = Manager()
    category_counter = manager.dict()
    category_counter['__global__'] = 0

    # ç»Ÿè®¡å·²å¯¼å‡ºçš„ç±»åˆ«æ•°é‡
    if enable_category_limit := export_settings.get('enable_category_limit', False):
        for ann in all_annotations_list:
            cat_id = ann.get('category_id')
            for cat in categories_data:
                if cat['id'] == cat_id:
                    cat_name = cat['name']
                    category_counter[cat_name] = category_counter.get(cat_name, 0) + 1
                    category_counter['__global__'] = category_counter.get('__global__', 0) + 1
                    break
        logger.info(f"ğŸ“Š å·²å¯¼å‡ºç»Ÿè®¡: {dict(category_counter)}")

    # ã€æ–°åŠŸèƒ½ã€‘éšæœºæ‰“ä¹±åºåˆ—é¡ºåºï¼Œç¡®ä¿éšæœºæå–
    import random
    sequences_shuffled = sequences.copy()
    random.shuffle(sequences_shuffled)
    logger.info(f"ğŸ”€ å·²éšæœºæ‰“ä¹± {len(sequences_shuffled)} ä¸ªåºåˆ—çš„å¤„ç†é¡ºåº")

    # è·å–ç±»åˆ«é™åˆ¶é…ç½®
    category_limit_config = export_settings.get('category_limit_config', {})
    per_category_limit = category_limit_config.get('per_category_limit', float('inf'))

    # åˆ›å»ºç±»åˆ«IDåˆ°åç§°çš„æ˜ å°„
    category_id_to_name = {cat['id']: cat['name'] for cat in categories_data}

    process_args = []
    temp_bbox_seq_counter = bbox_seq_counter

    # ã€ä¼˜åŒ–ã€‘åœ¨æ·»åŠ åˆ°process_argsæ—¶å°±æ£€æŸ¥ç±»åˆ«é™åˆ¶
    for seq in sequences_shuffled:
        # è·³è¿‡å·²å®Œæˆçš„åºåˆ—
        if seq['sequence_id'] in completed_source_seq_ids:
            logger.info(translation['info_skipping_completed_sequence'].format(seq['sequence_id']))
            continue

        # è·å–è¯¥åºåˆ—çš„æ‰€æœ‰æ ‡æ³¨
        seq_annotations = annotations_data.get(seq['sequence_id'], {}).get(seq['last_image_path'], [])
        if not seq_annotations:
            continue

        # ã€æ–°åŠŸèƒ½ã€‘æ£€æŸ¥è¯¥åºåˆ—ä¸­çš„æ¯ä¸ªæ ‡æ³¨æ‰€å±ç±»åˆ«æ˜¯å¦å·²è¾¾é™åˆ¶
        if enable_category_limit:
            all_categories_full = True
            for ann in seq_annotations:
                cat_id = ann.get('category_id')
                cat_name = category_id_to_name.get(cat_id, 'unknown')
                current_count = category_counter.get(cat_name, 0)

                if current_count < per_category_limit:
                    all_categories_full = False
                    break

            # å¦‚æœè¯¥åºåˆ—çš„æ‰€æœ‰æ ‡æ³¨æ‰€å±ç±»åˆ«éƒ½å·²è¾¾åˆ°é™åˆ¶ï¼Œè·³è¿‡
            if all_categories_full:
                continue

        ann_count = len(seq_annotations)
        process_args.append((
            seq, base_folder, output_path, has_images2, temp_bbox_seq_counter,
            annotations_only, language, debug, initial_bbox_seq_counter,
            config, category_counter  # ã€æ–°å¢ã€‘ä¼ é€’é…ç½®å’Œè®¡æ•°å™¨
        ))
        temp_bbox_seq_counter += ann_count

    if not process_args:
        logger.info("æ‰€æœ‰åºåˆ—å‡å·²å¤„ç†å®Œæ¯•ï¼Œæ— éœ€æ‰§è¡Œæ–°ä»»åŠ¡ã€‚")
        return

    with multiprocessing.Pool(processes=num_cores, initializer=init_worker, initargs=(annotations_data, categories_data, images_data)) as pool:
        results = pool.map(process_sequence, process_args)

    first_image_id_map = {}
    for local_images, local_annotations, _ in results:
        if not local_images: continue

        for img in local_images:
            img['id'] = image_id_counter
            if img['sequence_id'] not in first_image_id_map:
                first_image_id_map[img['sequence_id']] = img['id']
            all_images_list.append(img)
            image_id_counter += 1

        for ann in local_annotations:
            ann['id'] = annotation_id_counter
            first_img_id = first_image_id_map.get(ann['image_id'])
            if first_img_id:
                ann['image_id'] = first_img_id
                all_annotations_list.append(ann)
                annotation_id_counter += 1
            else:
                 logger.warning(translation['warning_annotation_dropped_no_image'].format(ann['sequence_id']))

    logger.info(translation['info_saving_annotations_json_file'])
    
    final_categories = list({cat['name']: cat for cat in categories_data}.values())

    class_anno_data = {
        "info": {"description": translation['dataset_description_classification'], "year": datetime.now().year},
        "images": all_images_list,
        "annotations": all_annotations_list,
        "categories": final_categories
    }
    with open(export_annotations_file, 'w', encoding='utf-8') as f:
        json.dump(class_anno_data, f, ensure_ascii=False, indent=4)
    
    logger.info(translation['info_classification_dataset_exported'])
    logger.info(translation['info_export_success_path'].format(output_path))
    # Ensure SyncManager terminates cleanly to avoid BrokenPipe/EOFError noise at shutdown
    try:
        manager.shutdown()
    except Exception:
        pass

# ==================== å‘½ä»¤è¡Œæ¥å£ ====================
if __name__ == "__main__":
    multiprocessing.freeze_support()

    parser = argparse.ArgumentParser(
        description="ä»æ£€æµ‹æ•°æ®é›†å¯¼å‡ºåˆ†ç±»æ•°æ®é›† - æ”¯æŒè¾¹ç•Œæ¡†æ‰©å¼ å’Œç±»åˆ«é™åˆ¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  åŸºç¡€å¯¼å‡º:
    python auto_biocate1.py --detection_dir /path/to/detection --export_dir /path/to/export

  ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶:
    python auto_biocate1.py --detection_dir /path/to/detection --export_dir /path/to/export --config custom_config.json

  å¯ç”¨è°ƒè¯•æ¨¡å¼:
    python auto_biocate1.py --detection_dir /path/to/detection --export_dir /path/to/export --debug

é…ç½®æ–‡ä»¶è¯´æ˜:
  é…ç½®æ–‡ä»¶é»˜è®¤ä¸º auto_biocate1_config.jsonï¼Œå¯é€šè¿‡ --config å‚æ•°æŒ‡å®š
  é…ç½®é¡¹åŒ…æ‹¬:
    - enable_bbox_expansion: å¯ç”¨è¾¹ç•Œæ¡†æ‰©å¼ 
    - enable_category_limit: å¯ç”¨ç±»åˆ«å¯¼å‡ºæ•°é‡é™åˆ¶
        """)

    parser.add_argument('--detection_dir', required=True, help="æ£€æµ‹æ•°æ®é›†è·¯å¾„")
    parser.add_argument('--export_dir', required=True, help="å¯¼å‡ºåˆ†ç±»æ•°æ®é›†è·¯å¾„")
    parser.add_argument('--num_cores', type=int, default=multiprocessing.cpu_count(), help="ä½¿ç”¨çš„CPUæ ¸å¿ƒæ•° (é»˜è®¤: æ‰€æœ‰æ ¸å¿ƒ)")
    parser.add_argument('--language', default='zh_CN', choices=['zh_CN', 'en'], help="è¯­è¨€ (zh_CN æˆ– en)")
    parser.add_argument('--annotations_only', action='store_true', help="ä»…ç”Ÿæˆannotations.jsonæ–‡ä»¶ï¼Œä¸è£åˆ‡å’Œä¿å­˜å›¾åƒ")
    parser.add_argument('--debug', action='store_true', help="åˆ›å»ºdebugæ–‡ä»¶å¤¹ï¼Œå¹¶å¤åˆ¶æœ¬æ¬¡å¯¼å‡ºçš„å‰10ä¸ªæ ·æœ¬ä»¥ä¾›å¿«é€ŸæŸ¥çœ‹")
    parser.add_argument('--config', default='auto_biocate1_config.json', help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: auto_biocate1_config.json)")

    args = parser.parse_args()

    export_classification_dataset(
        args.detection_dir,
        args.export_dir,
        args.num_cores,
        args.language,
        args.annotations_only,
        args.debug,
        args.config
    )
